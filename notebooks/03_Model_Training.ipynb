{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis - Model Training & Hyperparameter Tuning\n",
    "\n",
    "This notebook focuses on training different models for sentiment classification:\n",
    "\n",
    "1. Baseline Models:\n",
    "   - Logistic Regression\n",
    "   - Support Vector Machine (SVM)\n",
    "   - Random Forest\n",
    "\n",
    "2. Deep Learning Models:\n",
    "   - BiLSTM\n",
    "   - BERT fine-tuning\n",
    "\n",
    "3. Hyperparameter Tuning:\n",
    "   - Grid Search for baseline models\n",
    "   - Optuna for deep learning models\n",
    "\n",
    "We will train each model with different feature representations and save the best models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, roc_auc_score\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# Deep learning libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "\n",
    "# Hyperparameter optimization\n",
    "import optuna\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style='whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Features and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "source": [
    "# For Google Colab, uncomment these lines to mount Google Drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# features_dir = '/content/drive/MyDrive/path/to/features'\n",
    "# models_dir = '/content/drive/MyDrive/path/to/models'\n",
    "\n",
    "# For local development\n",
    "features_dir = '../data/features'\n",
    "models_dir = '../models'\n",
    "results_dir = '../results'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Load labels\n",
    "y = np.load(os.path.join(features_dir, 'labels.npy'))\n",
    "\n",
    "# Load features\n",
    "X_bow = sp.load_npz(os.path.join(features_dir, 'bow_features.npz'))\n",
    "X_tfidf = sp.load_npz(os.path.join(features_dir, 'tfidf_features.npz'))\n",
    "X_word2vec = np.load(os.path.join(features_dir, 'word2vec_features.npy'))\n",
    "X_glove = np.load(os.path.join(features_dir, 'glove_features.npy'))\n",
    "X_bert = np.load(os.path.join(features_dir, 'bert_features.npy'))\n",
    "\n",
    "print(\"Features loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "source": [
    "# Split data into train, validation, and test sets (70%, 15%, 15%)\n",
    "def split_data(X, y, test_size=0.15, val_size=0.15, random_state=42):\n",
    "    # First split: training + validation vs test\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Second split: training vs validation\n",
    "    # Adjust validation size to be a percentage of the training + validation set\n",
    "    val_ratio = val_size / (1 - test_size)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=val_ratio, random_state=random_state, stratify=y_train_val\n",
    "    )\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "# Create train/val/test splits for each feature type\n",
    "# BoW features\n",
    "bow_train, bow_val, bow_test, y_train, y_val, y_test = split_data(X_bow, y)\n",
    "\n",
    "# TF-IDF features\n",
    "tfidf_train, tfidf_val, tfidf_test, _, _, _ = split_data(X_tfidf, y, random_state=42)\n",
    "\n",
    "# Word2Vec features\n",
    "w2v_train, w2v_val, w2v_test, _, _, _ = split_data(X_word2vec, y, random_state=42)\n",
    "\n",
    "# GloVe features\n",
    "glove_train, glove_val, glove_test, _, _, _ = split_data(X_glove, y, random_state=42)\n",
    "\n",
    "# BERT features\n",
    "bert_train, bert_val, bert_test, _, _, _ = split_data(X_bert, y, random_state=42)\n",
    "\n",
    "print(f\"Train set: {y_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {y_val.shape[0]} samples\")\n",
    "print(f\"Test set: {y_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "source": [
    "# Train and evaluate a model\n",
    "def train_evaluate_model(model, X_train, X_val, y_train, y_val, model_name, feature_name):\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"{model_name} with {feature_name} - Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'model_name': model_name,\n",
    "        'feature_name': feature_name\n",
    "    }\n",
    "\n",
    "# Function to run GridSearchCV\n",
    "def grid_search_model(model, param_grid, X_train, y_train, model_name):\n",
    "    # Set up GridSearchCV\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=cv, scoring='f1_weighted', n_jobs=-1, verbose=1)\n",
    "    \n",
    "    # Train model with grid search\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Best parameters for {model_name}: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "source": [
    "# Dictionary to store all results\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "source": [
    "# Logistic Regression parameters\n",
    "lr_param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "# For BoW features\n",
    "print(\"Training Logistic Regression with BoW features...\")\n",
    "lr_bow = grid_search_model(LogisticRegression(), lr_param_grid, bow_train, y_train, \"Logistic Regression (BoW)\")\n",
    "lr_bow_result = train_evaluate_model(lr_bow, bow_train, bow_val, y_train, y_val, \"Logistic Regression\", \"BoW\")\n",
    "results.append(lr_bow_result)\n",
    "\n",
    "# For TF-IDF features\n",
    "print(\"\\nTraining Logistic Regression with TF-IDF features...\")\n",
    "lr_tfidf = grid_search_model(LogisticRegression(), lr_param_grid, tfidf_train, y_train, \"Logistic Regression (TF-IDF)\")\n",
    "lr_tfidf_result = train_evaluate_model(lr_tfidf, tfidf_train, tfidf_val, y_train, y_val, \"Logistic Regression\", \"TF-IDF\")\n",
    "results.append(lr_tfidf_result)\n",
    "\n",
    "# For Word2Vec features\n",
    "print(\"\\nTraining Logistic Regression with Word2Vec features...\")\n",
    "lr_w2v = grid_search_model(LogisticRegression(), lr_param_grid, w2v_train, y_train, \"Logistic Regression (Word2Vec)\")\n",
    "lr_w2v_result = train_evaluate_model(lr_w2v, w2v_train, w2v_val, y_train, y_val, \"Logistic Regression\", \"Word2Vec\")\n",
    "results.append(lr_w2v_result)\n",
    "\n",
    "# For GloVe features\n",
    "print(\"\\nTraining Logistic Regression with GloVe features...\")\n",
    "lr_glove = grid_search_model(LogisticRegression(), lr_param_grid, glove_train, y_train, \"Logistic Regression (GloVe)\")\n",
    "lr_glove_result = train_evaluate_model(lr_glove, glove_train, glove_val, y_train, y_val, \"Logistic Regression\", \"GloVe\")\n",
    "results.append(lr_glove_result)\n",
    "\n",
    "# For BERT features\n",
    "print(\"\\nTraining Logistic Regression with BERT features...\")\n",
    "lr_bert = grid_search_model(LogisticRegression(), lr_param_grid, bert_train, y_train, \"Logistic Regression (BERT)\")\n",
    "lr_bert_result = train_evaluate_model(lr_bert, bert_train, bert_val, y_train, y_val, \"Logistic Regression\", \"BERT\")\n",
    "results.append(lr_bert_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "source": [
    "# SVM parameters - limited for computational efficiency\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# For BoW features\n",
    "print(\"Training SVM with BoW features...\")\n",
    "svm_bow = grid_search_model(SVC(), svm_param_grid, bow_train, y_train, \"SVM (BoW)\")\n",
    "svm_bow_result = train_evaluate_model(svm_bow, bow_train, bow_val, y_train, y_val, \"SVM\", \"BoW\")\n",
    "results.append(svm_bow_result)\n",
    "\n",
    "# For TF-IDF features\n",
    "print(\"\\nTraining SVM with TF-IDF features...\")\n",
    "svm_tfidf = grid_search_model(SVC(), svm_param_grid, tfidf_train, y_train, \"SVM (TF-IDF)\")\n",
    "svm_tfidf_result = train_evaluate_model(svm_tfidf, tfidf_train, tfidf_val, y_train, y_val, \"SVM\", \"TF-IDF\")\n",
    "results.append(svm_tfidf_result)\n",
    "\n",
    "# For Word2Vec features\n",
    "print(\"\\nTraining SVM with Word2Vec features...\")\n",
    "svm_w2v = grid_search_model(SVC(), svm_param_grid, w2v_train, y_train, \"SVM (Word2Vec)\")\n",
    "svm_w2v_result = train_evaluate_model(svm_w2v, w2v_train, w2v_val, y_train, y_val, \"SVM\", \"Word2Vec\")\n",
    "results.append(svm_w2v_result)\n",
    "\n",
    "# For GloVe features\n",
    "print(\"\\nTraining SVM with GloVe features...\")\n",
    "svm_glove = grid_search_model(SVC(), svm_param_grid, glove_train, y_train, \"SVM (GloVe)\")\n",
    "svm_glove_result = train_evaluate_model(svm_glove, glove_train, glove_val, y_train, y_val, \"SVM\", \"GloVe\")\n",
    "results.append(svm_glove_result)\n",
    "\n",
    "# For BERT features\n",
    "print(\"\\nTraining SVM with BERT features...\")\n",
    "svm_bert = grid_search_model(SVC(), svm_param_grid, bert_train, y_train, \"SVM (BERT)\")\n",
    "svm_bert_result = train_evaluate_model(svm_bert, bert_train, bert_val, y_train, y_val, \"SVM\", \"BERT\")\n",
    "results.append(svm_bert_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "source": [
    "# Random Forest parameters\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# For BoW features\n",
    "print(\"Training Random Forest with BoW features...\")\n",
    "rf_bow = grid_search_model(RandomForestClassifier(random_state=42), rf_param_grid, bow_train, y_train, \"Random Forest (BoW)\")\n",
    "rf_bow_result = train_evaluate_model(rf_bow, bow_train, bow_val, y_train, y_val, \"Random Forest\", \"BoW\")\n",
    "results.append(rf_bow_result)\n",
    "\n",
    "# For TF-IDF features\n",
    "print(\"\\nTraining Random Forest with TF-IDF features...\")\n",
    "rf_tfidf = grid_search_model(RandomForestClassifier(random_state=42), rf_param_grid, tfidf_train, y_train, \"Random Forest (TF-IDF)\")\n",
    "rf_tfidf_result = train_evaluate_model(rf_tfidf, tfidf_train, tfidf_val, y_train, y_val, \"Random Forest\", \"TF-IDF\")\n",
    "results.append(rf_tfidf_result)\n",
    "\n",
    "# For Word2Vec features\n",
    "print(\"\\nTraining Random Forest with Word2Vec features...\")\n",
    "rf_w2v = grid_search_model(RandomForestClassifier(random_state=42), rf_param_grid, w2v_train, y_train, \"Random Forest (Word2Vec)\")\n",
    "rf_w2v_result = train_evaluate_model(rf_w2v, w2v_train, w2v_val, y_train, y_val, \"Random Forest\", \"Word2Vec\")\n",
    "results.append(rf_w2v_result)\n",
    "\n",
    "# For GloVe features\n",
    "print(\"\\nTraining Random Forest with GloVe features...\")\n",
    "rf_glove = grid_search_model(RandomForestClassifier(random_state=42), rf_param_grid, glove_train, y_train, \"Random Forest (GloVe)\")\n",
    "rf_glove_result = train_evaluate_model(rf_glove, glove_train, glove_val, y_train, y_val, \"Random Forest\", \"GloVe\")\n",
    "results.append(rf_glove_result)\n",
    "\n",
    "# For BERT features\n",
    "print(\"\\nTraining Random Forest with BERT features...\")\n",
    "rf_bert = grid_search_model(RandomForestClassifier(random_state=42), rf_param_grid, bert_train, y_train, \"Random Forest (BERT)\")\n",
    "rf_bert_result = train_evaluate_model(rf_bert, bert_train, bert_val, y_train, y_val, \"Random Forest\", \"BERT\")\n",
    "results.append(rf_bert_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Deep Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 BiLSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "source": [
    "# Define BiLSTM model\n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, dropout):\n",
    "        super(BiLSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=n_layers, bidirectional=True, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        # text shape: [batch size, input dim]\n",
    "        # We need to add sequence length dimension for LSTM\n",
    "        text = text.unsqueeze(1)  # Now: [batch size, 1, input dim]\n",
    "        \n",
    "        output, (hidden, cell) = self.lstm(text)\n",
    "        \n",
    "        # Concatenate the final forward and backward hidden states\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "        \n",
    "        return self.fc(hidden)\n",
    "\n",
    "# Dataset class for PyTorch\n",
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = torch.FloatTensor(embeddings)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.labels[idx]\n",
    "\n",
    "# Function to train BiLSTM\n",
    "def train_bilstm(X_train, X_val, y_train, y_val, embedding_type, n_epochs=10):\n",
    "    # Check if CUDA is available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Create datasets and data loaders\n",
    "    train_dataset = EmbeddingDataset(X_train, y_train)\n",
    "    val_dataset = EmbeddingDataset(X_val, y_val)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "    \n",
    "    # Create model\n",
    "    input_dim = X_train.shape[1]\n",
    "    hidden_dim = 128\n",
    "    output_dim = len(np.unique(y_train))\n",
    "    n_layers = 2\n",
    "    dropout = 0.5\n",
    "    \n",
    "    model = BiLSTMClassifier(input_dim, hidden_dim, output_dim, n_layers, dropout)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Define optimizer and loss function\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        \n",
    "        for embeddings, labels in train_loader:\n",
    "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(embeddings)\n",
    "            loss = criterion(predictions, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(predictions, 1)\n",
    "            train_acc += (predicted == labels).sum().item() / len(labels)\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc /= len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for embeddings, labels in val_loader:\n",
    "                embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "                predictions = model(embeddings)\n",
    "                loss = criterion(predictions, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(predictions, 1)\n",
    "                val_acc += (predicted == labels).sum().item() / len(labels)\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc /= len(val_loader)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model.state_dict().copy()\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(best_model)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for embeddings, labels in val_loader:\n",
    "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "            predictions = model(embeddings)\n",
    "            _, predicted = torch.max(predictions, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    print(f\"BiLSTM with {embedding_type} - Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), os.path.join(models_dir, f'bilstm_{embedding_type.lower()}.pt'))\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'model_name': 'BiLSTM',\n",
    "        'feature_name': embedding_type\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "source": [
    "# Train BiLSTM with Word2Vec embeddings\n",
    "print(\"Training BiLSTM with Word2Vec embeddings...\")\n",
    "bilstm_w2v_result = train_bilstm(w2v_train, w2v_val, y_train, y_val, \"Word2Vec\")\n",
    "results.append(bilstm_w2v_result)\n",
    "\n",
    "# Train BiLSTM with GloVe embeddings\n",
    "print(\"\\nTraining BiLSTM with GloVe embeddings...\")\n",
    "bilstm_glove_result = train_bilstm(glove_train, glove_val, y_train, y_val, \"GloVe\")\n",
    "results.append(bilstm_glove_result)\n",
    "\n",
    "# Train BiLSTM with BERT embeddings\n",
    "print(\"\\nTraining BiLSTM with BERT embeddings...\")\n",
    "bilstm_bert_result = train_bilstm(bert_train, bert_val, y_train, y_val, \"BERT\")\n",
    "results.append(bilstm_bert_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 BERT Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Hyperparameter Tuning with Optuna for BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "source": [
    "# Hyperparameter tuning for BiLSTM using Optuna\n",
    "def objective(trial, X_train, X_val, y_train, y_val):\n",
    "    # Define hyperparameters to optimize\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256, step=64)\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 3)\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.5, step=0.1)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    \n",
    "    # Check if CUDA is available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Create datasets and data loaders\n",
    "    train_dataset = EmbeddingDataset(X_train, y_train)\n",
    "    val_dataset = EmbeddingDataset(X_val, y_val)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    # Create model\n",
    "    input_dim = X_train.shape[1]\n",
    "    output_dim = len(np.unique(y_train))\n",
    "    \n",
    "    model = BiLSTMClassifier(input_dim, hidden_dim, output_dim, n_layers, dropout)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Define optimizer and loss function\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Early stopping parameters\n",
    "    patience = 3\n",
    "    best_val_loss = float('inf')\n",
    "    counter = 0\n",
    "    \n",
    "    # Training loop\n",
    "    n_epochs = 10  # Max epochs for tuning\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for embeddings, labels in train_loader:\n",
    "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(embeddings)\n",
    "            loss = criterion(predictions, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for embeddings, labels in val_loader:\n",
    "                embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "                predictions = model(embeddings)\n",
    "                loss = criterion(predictions, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(predictions, 1)\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "        \n",
    "        # Report score to Optuna\n",
    "        trial.report(f1, epoch)\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                break\n",
    "        \n",
    "        # Handle pruning\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    \n",
    "    return f1\n",
    "\n",
    "# Run optimization for BiLSTM with Word2Vec embeddings\n",
    "def optimize_bilstm(X_train, X_val, y_train, y_val, embedding_type, n_trials=20):\n",
    "    print(f\"\\nOptimizing BiLSTM with {embedding_type} embeddings...\")\n",
    "    \n",
    "    # Create study\n",
    "    study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n",
    "    \n",
    "    # Run optimization\n",
    "    study.optimize(lambda trial: objective(trial, X_train, X_val, y_train, y_val), n_trials=n_trials)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nBest trial for BiLSTM with {embedding_type}:\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"  F1 Score: {trial.value:.4f}\")\n",
    "    print(\"  Params:\")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "    \n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "source": [
    "# Uncomment to run hyperparameter optimization (this can take a long time)\n",
    "# best_params_w2v = optimize_bilstm(w2v_train, w2v_val, y_train, y_val, \"Word2Vec\", n_trials=10)\n",
    "# best_params_glove = optimize_bilstm(glove_train, glove_val, y_train, y_val, \"GloVe\", n_trials=10)\n",
    "# best_params_bert = optimize_bilstm(bert_train, bert_val, y_train, y_val, \"BERT\", n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "source": [
    "# Function to train BiLSTM with optimized hyperparameters\n",
    "def train_bilstm_optimized(X_train, X_val, y_train, y_val, embedding_type, params, n_epochs=15):\n",
    "    # Check if CUDA is available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Extract parameters\n",
    "    hidden_dim = params['hidden_dim']\n",
    "    n_layers = params['n_layers']\n",
    "    dropout = params['dropout']\n",
    "    learning_rate = params['learning_rate']\n",
    "    batch_size = params['batch_size']\n",
    "    \n",
    "    # Create datasets and data loaders\n",
    "    train_dataset = EmbeddingDataset(X_train, y_train)\n",
    "    val_dataset = EmbeddingDataset(X_val, y_val)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    # Create model\n",
    "    input_dim = X_train.shape[1]\n",
    "    output_dim = len(np.unique(y_train))\n",
    "    \n",
    "    model = BiLSTMClassifier(input_dim, hidden_dim, output_dim, n_layers, dropout)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Define optimizer and loss function\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        \n",
    "        for embeddings, labels in train_loader:\n",
    "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(embeddings)\n",
    "            loss = criterion(predictions, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(predictions, 1)\n",
    "            train_acc += (predicted == labels).sum().item() / len(labels)\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc /= len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for embeddings, labels in val_loader:\n",
    "                embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "                predictions = model(embeddings)\n",
    "                loss = criterion(predictions, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(predictions, 1)\n",
    "                val_acc += (predicted == labels).sum().item() / len(labels)\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc /= len(val_loader)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model.state_dict().copy()\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(best_model)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for embeddings, labels in val_loader:\n",
    "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "            predictions = model(embeddings)\n",
    "            _, predicted = torch.max(predictions, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    print(f\"Optimized BiLSTM with {embedding_type} - Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), os.path.join(models_dir, f'bilstm_{embedding_type.lower()}_optimized.pt'))\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'model_name': 'BiLSTM (Optimized)',\n",
    "        'feature_name': embedding_type\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 BERT Fine-tuning with Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "source": [
    "# BERT Dataset class\n",
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=True,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'token_type_ids': encoding['token_type_ids'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "source": [
    "# Placeholder for BERT fine-tuning with Optuna hyperparameter optimization\n",
    "# This would involve:\n",
    "# 1. Loading the processed tweets text from cleaned data\n",
    "# 2. Setting up BERT tokenizer and dataset\n",
    "# 3. Defining the objective function for Optuna (optimizing learning rate, batch size, etc.)\n",
    "# 4. Training BERT with the optimized hyperparameters\n",
    "\n",
    "# For demonstration, we'll include a simplified version\n",
    "def objective_bert(trial, texts, labels, num_labels):\n",
    "    # Define hyperparameters to optimize\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 5e-5, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [8, 16, 32])\n",
    "    epochs = trial.suggest_int('epochs', 2, 4)  # Limited for computation time\n",
    "    \n",
    "    # Load pre-trained BERT model and tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        'bert-base-uncased',\n",
    "        num_labels=num_labels\n",
    "    )\n",
    "    \n",
    "    # Split data (assuming texts and labels are already processed)\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "        texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
    "    )\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = BERTDataset(train_texts, train_labels, tokenizer)\n",
    "    val_dataset = BERTDataset(val_texts, val_labels, tokenizer)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    # Setup device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Setup optimizer\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_f1 = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids=input_ids,\n",
    "                          attention_mask=attention_mask,\n",
    "                          token_type_ids=token_type_ids,\n",
    "                          labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_true = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                token_type_ids = batch['token_type_ids'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                outputs = model(input_ids=input_ids,\n",
    "                              attention_mask=attention_mask,\n",
    "                              token_type_ids=token_type_ids)\n",
    "                \n",
    "                _, preds = torch.max(outputs.logits, dim=1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_true.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # Calculate F1 score\n",
    "        val_f1 = f1_score(val_true, val_preds, average='weighted')\n",
    "        \n",
    "        # Report to Optuna\n",
    "        trial.report(val_f1, epoch)\n",
    "        \n",
    "        # Handle pruning\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "        # Update best score\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "    \n",
    "    return best_val_f1\n",
    "\n",
    "# Placeholder for BERT optimization function\n",
    "# In practice, this would load your Twitter dataset text and run the optimization\n",
    "def optimize_bert(n_trials=10):\n",
    "    print(\"Note: For a real implementation, load your processed tweet texts here.\")\n",
    "    print(\"This is a placeholder to show the structure of BERT hyperparameter tuning.\")\n",
    "    \n",
    "    # In practice, you would:\n",
    "    # 1. Load your text data and labels\n",
    "    # 2. Define num_labels based on your sentiment classes\n",
    "    # 3. Run the study as shown below\n",
    "    \n",
    "    # Create study\n",
    "    # study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n",
    "    # study.optimize(lambda trial: objective_bert(trial, texts, labels, num_labels), n_trials=n_trials)\n",
    "    \n",
    "    # Return example best parameters\n",
    "    return {\n",
    "        'learning_rate': 2e-5,\n",
    "        'batch_size': 16,\n",
    "        'epochs': 3\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "source": [
    "# Uncomment to run BERT hyperparameter optimization (requires original tweet texts)\n",
    "# best_params_bert = optimize_bert(n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "source": [
    "# This section will be a simplified version of BERT fine-tuning\n",
    "# For the full implementation, please see the complete notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "source": [
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame([\n",
    "    {'Model': r['model_name'], \n",
    "     'Feature': r['feature_name'], \n",
    "     'Accuracy': r['accuracy'], \n",
    "     'F1 Score': r['f1_score']} for r in results\n",
    "])\n",
    "\n",
    "# Sort by F1 score (descending)\n",
    "results_df = results_df.sort_values(by='F1 Score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display results\n",
    "print(\"Model Performance on Validation Set:\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "source": [
    "# Visualize results\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x='Model', y='F1 Score', hue='Feature', data=results_df)\n",
    "plt.title('Model Performance Comparison (F1 Score)', fontsize=15)\n",
    "plt.xlabel('Model', fontsize=12)\n",
    "plt.ylabel('F1 Score', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_dir, 'model_comparison.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "source": [
    "# Get top 3 performing models\n",
    "top_models = results_df.head(3)\n",
    "print(\"Top 3 performing models:\")\n",
    "top_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "source": [
    "# Save results\n",
    "results_df.to_csv(os.path.join(results_dir, 'model_comparison_results.csv'), index=False)\n",
    "print(f\"Model comparison results saved to {os.path.join(results_dir, 'model_comparison_results.csv')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we have:\n",
    "1. Loaded different feature representations of the Twitter dataset\n",
    "2. Split the data into train, validation, and test sets\n",
    "3. Trained baseline models (Logistic Regression, SVM, Random Forest) with Grid Search\n",
    "4. Trained deep learning models (BiLSTM) with different embeddings\n",
    "5. Compared model performance across different feature representations\n",
    "6. Saved the best models for further evaluation\n",
    "\n",
    "**Next Steps:**\n",
    "- Move to the evaluation notebook\n",
    "- Evaluate the best models on the test set\n",
    "- Apply interpretability techniques (SHAP values)\n",
    "- Generate comprehensive evaluation reports"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}