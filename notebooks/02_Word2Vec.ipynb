{"cells":[{"cell_type":"markdown","source":["# Feature Engineering (Word2Vec)"],"metadata":{"id":"ZINXVL-b1VS5"}},{"cell_type":"markdown","metadata":{"id":"R5Yi1958faS5"},"source":["## Setup and Imports\n","\n","- the implemenetation of Word2Vec is separated from other features since a earlier version of numpy is needed\n","- you might need to restart session after installation"]},{"cell_type":"code","source":["!pip install gensim\n","!pip install --force-reinstall -v \"numpy==1.24.2\""],"metadata":{"id":"8QW6v62Jge4n","executionInfo":{"status":"ok","timestamp":1744307621650,"user_tz":-480,"elapsed":7756,"user":{"displayName":"Wong Matthew","userId":"12913150185447736015"}},"colab":{"base_uri":"https://localhost:8080/","height":867},"outputId":"7af73e34-3188-47e2-fc35-b0856cd882f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n","Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.24.2)\n","Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n","Using pip 24.1.2 from /usr/local/lib/python3.11/dist-packages/pip (python 3.11)\n","  Link requires a different Python (3.11.12 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/3a/be/650f9c091ef71cb01d735775d554e068752d3ff63d7943b26316dc401749/numpy-1.21.2.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\n","  Link requires a different Python (3.11.12 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/5f/d6/ad58ded26556eaeaa8c971e08b6466f17c4ac4d786cd3d800e26ce59cc01/numpy-1.21.3.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\n","  Link requires a different Python (3.11.12 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/fb/48/b0708ebd7718a8933f0d3937513ef8ef2f4f04529f1f66ca86d873043921/numpy-1.21.4.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\n","  Link requires a different Python (3.11.12 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/c2/a8/a924a09492bdfee8c2ec3094d0a13f2799800b4fdc9c890738aeeb12c72e/numpy-1.21.5.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\n","  Link requires a different Python (3.11.12 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/45/b7/de7b8e67f2232c26af57c205aaad29fe17754f793404f59c8a730c7a191a/numpy-1.21.6.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\n","Collecting numpy==1.24.2\n","  Obtaining dependency information for numpy==1.24.2 from https://files.pythonhosted.org/packages/b6/d7/b208a4a534732e4a978003768ac7b8c14fcd4ca5b1653ce4fb4c2826f3a4/numpy-1.24.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n","  Using cached numpy-1.24.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n","Using cached numpy-1.24.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n","Installing collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.24.2\n","    Uninstalling numpy-1.24.2:\n","      Removing file or directory /usr/local/bin/f2py\n","      Removing file or directory /usr/local/bin/f2py3\n","      Removing file or directory /usr/local/bin/f2py3.11\n","      Removing file or directory /usr/local/lib/python3.11/dist-packages/numpy-1.24.2.dist-info/\n","      Removing file or directory /usr/local/lib/python3.11/dist-packages/numpy.libs/\n","      Removing file or directory /usr/local/lib/python3.11/dist-packages/numpy/\n","      Successfully uninstalled numpy-1.24.2\n","  changing mode of /usr/local/bin/f2py to 755\n","  changing mode of /usr/local/bin/f2py3 to 755\n","  changing mode of /usr/local/bin/f2py3.11 to 755\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.24.2 which is incompatible.\n","pymc 5.21.2 requires numpy>=1.25.0, but you have numpy 1.24.2 which is incompatible.\n","treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.2 which is incompatible.\n","tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.2 which is incompatible.\n","albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.24.2 which is incompatible.\n","imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.24.2 which is incompatible.\n","jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.2 which is incompatible.\n","jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.2 which is incompatible.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.2 which is incompatible.\n","blosc2 3.2.1 requires numpy>=1.26, but you have numpy 1.24.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.24.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"20ee4540cef745219d1bfa14c3fedd6a"}},"metadata":{}}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"241rApRbfaS6"},"source":["# Core libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pickle\n","import os\n","from ast import literal_eval\n","\n","# Word embeddings\n","import gensim\n","from gensim.models import Word2Vec\n","\n","# Visualization settings\n","plt.style.use('ggplot')\n","sns.set(style='whitegrid')\n","%matplotlib inline"],"outputs":[]},{"cell_type":"markdown","metadata":{"id":"61fQ8aZcfaS6"},"source":["## Load Cleaned Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3_5J1SPsfaS7","executionInfo":{"status":"ok","timestamp":1744307668705,"user_tz":-480,"elapsed":2395,"user":{"displayName":"Wong Matthew","userId":"12913150185447736015"}},"outputId":"ea3aa204-d30b-4978-f94b-980d18bd8c8d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","train_path = '/content/drive/MyDrive/Colab Notebooks/is5126/final-project/data/twitter_training_clean.csv'\n","val_path = '/content/drive/MyDrive/Colab Notebooks/is5126/final-project/data/twitter_validation_clean.csv'\n","test_path = '/content/drive/MyDrive/Colab Notebooks/is5126/final-project/data/twitter_testing_clean.csv'\n","\n","# Load pre-split datasets\n","train_df = pd.read_csv(train_path)\n","val_df = pd.read_csv(val_path)\n","test_df = pd.read_csv(test_path)\n","\n","print(f\"Train set: {train_df.shape[0]} samples\")\n","print(f\"Validation set: {val_df.shape[0]} samples\")\n","print(f\"Test set: {test_df.shape[0]} samples\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Train set: 108000 samples\n","Validation set: 22107 samples\n","Test set: 22107 samples\n"]}]},{"cell_type":"markdown","metadata":{"id":"CoWxbCiXfaS8"},"source":["## Create Output Directories"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IJuhlSClfaS8"},"source":["# Create directories for saving features\n","features_dir = '/content/drive/MyDrive/Colab Notebooks/is5126/final-project/data/features'\n","os.makedirs(features_dir, exist_ok=True)\n","\n","# Paths for different feature types\n","word2vec_path = os.path.join(features_dir, 'word2vec_features.npy')\n","\n","# Path for saving vectorizers\n","models_dir = '/content/drive/MyDrive/Colab Notebooks/is5126/final-project/models'\n","os.makedirs(models_dir, exist_ok=True)\n","\n","word2vec_model_path = os.path.join(models_dir, 'word2vec_model')"],"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AUCxJH6sfaS9"},"source":["## Prepare Labels for Model Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1dKPueAtfaS9","executionInfo":{"status":"ok","timestamp":1744307677072,"user_tz":-480,"elapsed":61,"user":{"displayName":"Wong Matthew","userId":"12913150185447736015"}},"outputId":"574124d6-2c4e-4d4f-c563-a172fb3bb936"},"source":["from sklearn.preprocessing import LabelEncoder\n","\n","# Encode sentiment labels\n","label_encoder = LabelEncoder()\n","y = label_encoder.fit_transform(train_df['sentiment'])\n","\n","# Display the encoding mapping\n","print(\"Label Encoding:\")\n","for i, label in enumerate(label_encoder.classes_):\n","    print(f\"{label} -> {i}\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["Label Encoding:\n","Irrelevant -> 0\n","Negative -> 1\n","Neutral -> 2\n","Positive -> 3\n"]}]},{"cell_type":"markdown","metadata":{"id":"fWtSMqEafaS-"},"source":["### Word2Vec Embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NLgPtmiafaS_","executionInfo":{"status":"ok","timestamp":1744307829966,"user_tz":-480,"elapsed":152898,"user":{"displayName":"Wong Matthew","userId":"12913150185447736015"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5657121e-2e3c-4143-93ec-7966cb4fb9a4"},"source":["# Train Word2Vec model on the training dataset\n","print(\"Training Word2Vec model...\")\n","word2vec_model = Word2Vec(train_df['tokens'].tolist(),\n","                          vector_size=100,\n","                          window=5,\n","                          min_count=5,\n","                          workers=4,\n","                          sg=1) # Skip-gram model\n","\n","# Save the model for future use\n","word2vec_model.save(word2vec_model_path)\n","print(f\"Word2Vec model saved to {word2vec_model_path}\")\n","\n","# Function to create document vectors by averaging word vectors\n","def get_doc_vector(tokens, model, vector_size=100):\n","    # Initialize an empty array\n","    doc_vector = np.zeros(vector_size)\n","    count = 0\n","\n","    # Average the word vectors for each token in the document\n","    for token in tokens:\n","        if token in model.wv:\n","            doc_vector += model.wv[token]\n","            count += 1\n","\n","    # Avoid division by zero\n","    if count > 0:\n","        doc_vector /= count\n","\n","    return doc_vector\n","\n","# Generate Word2Vec features for each dataset\n","print(\"Generating Word2Vec features for train, validation, and test datasets...\")\n","X_train_word2vec = np.array([get_doc_vector(tokens, word2vec_model) for tokens in train_df['tokens']])\n","X_val_word2vec = np.array([get_doc_vector(tokens, word2vec_model) for tokens in val_df['tokens']])\n","X_test_word2vec = np.array([get_doc_vector(tokens, word2vec_model) for tokens in test_df['tokens']])\n","\n","print(f\"Word2Vec features shape (train): {X_train_word2vec.shape}\")\n","print(f\"Word2Vec features shape (val): {X_val_word2vec.shape}\")\n","print(f\"Word2Vec features shape (test): {X_test_word2vec.shape}\")\n","\n","# Save Word2Vec features\n","np.save(word2vec_path.replace('.npy', '_train.npy'), X_train_word2vec)\n","np.save(word2vec_path.replace('.npy', '_val.npy'), X_val_word2vec)\n","np.save(word2vec_path.replace('.npy', '_test.npy'), X_test_word2vec)\n","print(f\"Word2Vec features saved to {word2vec_path}\")"],"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"]},{"output_type":"stream","name":"stdout","text":["Training Word2Vec model...\n","Word2Vec model saved to /content/drive/MyDrive/Colab Notebooks/is5126/final-project/models/word2vec_model\n","Generating Word2Vec features for train, validation, and test datasets...\n","Word2Vec features shape (train): (108000, 100)\n","Word2Vec features shape (val): (22107, 100)\n","Word2Vec features shape (test): (22107, 100)\n","Word2Vec features saved to /content/drive/MyDrive/Colab Notebooks/is5126/final-project/data/features/word2vec_features.npy\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}