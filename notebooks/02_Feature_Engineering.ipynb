{"cells":[{"cell_type":"markdown","metadata":{"id":"x7ft22OgfaS4"},"source":["# Twitter Sentiment Analysis - Feature Engineering\n","\n","1. Traditional approaches:\n","   - Bag of Words (BoW)\n","   - Term Frequency-Inverse Document Frequency (TF-IDF)\n","\n","2. Word embeddings:\n","   - Word2Vec (in 02_Word2Vec.ipynb)\n","   - GloVe\n","\n","3. Contextual embeddings:\n","   - BERT"]},{"cell_type":"markdown","metadata":{"id":"R5Yi1958faS5"},"source":["## 1. Setup and Imports"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"241rApRbfaS6","executionInfo":{"status":"ok","timestamp":1743676955079,"user_tz":-480,"elapsed":16734,"user":{"displayName":"Wong Matthew","userId":"12913150185447736015"}}},"source":["# Core libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pickle\n","import os\n","from ast import literal_eval\n","\n","# Traditional NLP feature extraction\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","\n","# Word embeddings\n","# import gensim\n","# from gensim.models import Word2Vec\n","\n","# For BERT\n","import torch\n","from transformers import BertTokenizer, BertModel\n","\n","# Visualization settings\n","plt.style.use('ggplot')\n","sns.set(style='whitegrid')\n","%matplotlib inline"],"outputs":[]},{"cell_type":"markdown","metadata":{"id":"61fQ8aZcfaS6"},"source":["## 2. Load Cleaned Dataset"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3_5J1SPsfaS7","executionInfo":{"status":"ok","timestamp":1743676999512,"user_tz":-480,"elapsed":44430,"user":{"displayName":"Wong Matthew","userId":"12913150185447736015"}},"outputId":"fad03ec5-fa82-4aca-a946-0aceae5a64a6"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","dataset_path = '/content/drive/MyDrive/Colab Notebooks/is5126/final-project/data/twitter_training_clean.csv'\n","\n","# Load dataset\n","try:\n","    df = pd.read_csv(dataset_path)\n","    print(f\"Cleaned dataset loaded with shape: {df.shape}\")\n","except Exception as e:\n","    print(f\"Error loading dataset: {e}\")\n","    print(\"Please update the dataset path or ensure the preprocessing notebook has been run.\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Cleaned dataset loaded with shape: (71255, 5)\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"th_3j7fnfaS7","executionInfo":{"status":"ok","timestamp":1743677001550,"user_tz":-480,"elapsed":2035,"user":{"displayName":"Wong Matthew","userId":"12913150185447736015"}},"outputId":"f2c157b9-edd9-4c41-cb5c-39855b4a6e24"},"source":["# Convert tokens from string representation back to list\n","df['tokens'] = df['tokens'].apply(lambda x: literal_eval(x) if isinstance(x, str) else x)\n","\n","# Display the first few rows\n","df.head()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             content  \\\n","0  I am coming to the borders and I will kill you...   \n","1  im getting on borderlands and i will kill you ...   \n","2  im coming on borderlands and i will murder you...   \n","3  im getting on borderlands 2 and i will murder ...   \n","4  im getting into borderlands and i can murder y...   \n","\n","                  cleaned_content                                tokens  \\\n","0              coming border kill                [coming, border, kill]   \n","1      im getting borderland kill       [im, getting, borderland, kill]   \n","2     im coming borderland murder      [im, coming, borderland, murder]   \n","3  im getting borderland 2 murder  [im, getting, borderland, 2, murder]   \n","4    im getting borderland murder     [im, getting, borderland, murder]   \n","\n","        entity sentiment  \n","0  Borderlands  Positive  \n","1  Borderlands  Positive  \n","2  Borderlands  Positive  \n","3  Borderlands  Positive  \n","4  Borderlands  Positive  "],"text/html":["\n","  <div id=\"df-9dec1959-a342-4ff6-a04e-b7917d1898ab\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>content</th>\n","      <th>cleaned_content</th>\n","      <th>tokens</th>\n","      <th>entity</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I am coming to the borders and I will kill you...</td>\n","      <td>coming border kill</td>\n","      <td>[coming, border, kill]</td>\n","      <td>Borderlands</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>im getting on borderlands and i will kill you ...</td>\n","      <td>im getting borderland kill</td>\n","      <td>[im, getting, borderland, kill]</td>\n","      <td>Borderlands</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>im coming on borderlands and i will murder you...</td>\n","      <td>im coming borderland murder</td>\n","      <td>[im, coming, borderland, murder]</td>\n","      <td>Borderlands</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>im getting on borderlands 2 and i will murder ...</td>\n","      <td>im getting borderland 2 murder</td>\n","      <td>[im, getting, borderland, 2, murder]</td>\n","      <td>Borderlands</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>im getting into borderlands and i can murder y...</td>\n","      <td>im getting borderland murder</td>\n","      <td>[im, getting, borderland, murder]</td>\n","      <td>Borderlands</td>\n","      <td>Positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9dec1959-a342-4ff6-a04e-b7917d1898ab')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-9dec1959-a342-4ff6-a04e-b7917d1898ab button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-9dec1959-a342-4ff6-a04e-b7917d1898ab');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-5d991ff1-6359-40ab-a509-2614673c65a9\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5d991ff1-6359-40ab-a509-2614673c65a9')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-5d991ff1-6359-40ab-a509-2614673c65a9 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 71255,\n  \"fields\": [\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 68764,\n        \"samples\": [\n          \"This why almost stopped playing Madden. this shit use still get under my skin\",\n          \"Apple you big gay for removing Fortnite like fr you just lost A lot of customers smh pic.twitter.com/L8Dqhubzne\",\n          \"Nvidia GeForce Now: Google's rival Stadia suffers another blow news89.net / nvidia-geforce...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 62221,\n        \"samples\": [\n          \"borderland 3 ps4 amazing grace legendary revolver dlvr rnnx2z\",\n          \"people never yet seem realise even wealth management generational load business also subsidized till turn around\",\n          \"tiktok \\u2018 uncool \\u2019 12 song love music com tiktok un\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"entity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 32,\n        \"samples\": [\n          \"Cyberpunk2077\",\n          \"Microsoft\",\n          \"TomClancysRainbowSix\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Neutral\",\n          \"Irrelevant\",\n          \"Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"CoWxbCiXfaS8"},"source":["## 3. Create Output Directories"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"IJuhlSClfaS8","executionInfo":{"status":"ok","timestamp":1743677001557,"user_tz":-480,"elapsed":6,"user":{"displayName":"Wong Matthew","userId":"12913150185447736015"}}},"source":["# Create directories for saving features\n","features_dir = '/content/drive/MyDrive/Colab Notebooks/is5126/final-project/data/features'\n","os.makedirs(features_dir, exist_ok=True)\n","\n","# Paths for different feature types\n","bow_path = os.path.join(features_dir, 'bow_features.npz')\n","tfidf_path = os.path.join(features_dir, 'tfidf_features.npz')\n","word2vec_path = os.path.join(features_dir, 'word2vec_features.npy')\n","glove_path = os.path.join(features_dir, 'glove_features.npy')\n","bert_path = os.path.join(features_dir, 'bert_features.npy')\n","\n","# Path for saving vectorizers\n","models_dir = '/content/drive/MyDrive/Colab Notebooks/is5126/final-project/models'\n","os.makedirs(models_dir, exist_ok=True)\n","\n","bow_vectorizer_path = os.path.join(models_dir, 'bow_vectorizer.pkl')\n","tfidf_vectorizer_path = os.path.join(models_dir, 'tfidf_vectorizer.pkl')\n","word2vec_model_path = os.path.join(models_dir, 'word2vec_model')"],"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AUCxJH6sfaS9"},"source":["## 4. Prepare Labels for Model Training"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1dKPueAtfaS9","executionInfo":{"status":"ok","timestamp":1743677001846,"user_tz":-480,"elapsed":286,"user":{"displayName":"Wong Matthew","userId":"12913150185447736015"}},"outputId":"d0b04b0e-1e64-43a2-abbc-dae55b61ce81"},"source":["# Create label encoding for sentiment\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Encode sentiment labels\n","label_encoder = LabelEncoder()\n","y = label_encoder.fit_transform(df['sentiment'])\n","\n","# Display the encoding mapping\n","print(\"Label Encoding:\")\n","for i, label in enumerate(label_encoder.classes_):\n","    print(f\"{label} -> {i}\")\n","\n","# Save the label encoder\n","with open(os.path.join(models_dir, 'label_encoder.pkl'), 'wb') as f:\n","    pickle.dump(label_encoder, f)"],"outputs":[{"output_type":"stream","name":"stdout","text":["Label Encoding:\n","Irrelevant -> 0\n","Negative -> 1\n","Neutral -> 2\n","Positive -> 3\n"]}]},{"cell_type":"markdown","metadata":{"id":"aBgZzY0wfaS9"},"source":["## 5. Feature Engineering Approaches"]},{"cell_type":"markdown","metadata":{"id":"QMxdOLB2faS-"},"source":["### 5.1 Bag of Words (BoW)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IjOK18upfaS-","executionInfo":{"status":"ok","timestamp":1743677003556,"user_tz":-480,"elapsed":1707,"user":{"displayName":"Wong Matthew","userId":"12913150185447736015"}},"outputId":"19868039-15b3-4b24-ad9e-531c166a6c44"},"source":["# Initialize CountVectorizer\n","print(\"Creating Bag of Words features...\")\n","bow_vectorizer = CountVectorizer(max_features=5000, min_df=5)\n","\n","# Fit and transform the cleaned tweets\n","print(df['content'].isna().sum())\n","print(df['cleaned_content'].isna().sum())\n","\n","\n","df_filtered = df[df['cleaned_content'].isna()].copy()\n","\n","print(df_filtered)\n","\n","X_bow = bow_vectorizer.fit_transform(df['cleaned_content'])\n","\n","print(f\"BoW features shape: {X_bow.shape}\")\n","print(f\"Vocabulary size: {len(bow_vectorizer.vocabulary_)}\")\n","\n","# Save BoW features and vectorizer\n","import scipy.sparse as sp\n","sp.save_npz(bow_path, X_bow)\n","with open(bow_vectorizer_path, 'wb') as f:\n","    pickle.dump(bow_vectorizer, f)\n","\n","print(f\"BoW features saved to {bow_path}\")\n","print(f\"BoW vectorizer saved to {bow_vectorizer_path}\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["Creating Bag of Words features...\n","0\n","0\n","Empty DataFrame\n","Columns: [content, cleaned_content, tokens, entity, sentiment]\n","Index: []\n","BoW features shape: (71255, 5000)\n","Vocabulary size: 5000\n","BoW features saved to /content/drive/MyDrive/Colab Notebooks/is5126/final-project/data/features/bow_features.npz\n","BoW vectorizer saved to /content/drive/MyDrive/Colab Notebooks/is5126/final-project/models/bow_vectorizer.pkl\n"]}]},{"cell_type":"markdown","metadata":{"id":"TDYBd6WhfaS-"},"source":["### 5.2 TF-IDF"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G_HzAHc9faS-","executionInfo":{"status":"ok","timestamp":1743677006603,"user_tz":-480,"elapsed":3041,"user":{"displayName":"Wong Matthew","userId":"12913150185447736015"}},"outputId":"bde08dda-443e-486a-9ca5-d85b301a1eb3"},"source":["# Initialize TF-IDF Vectorizer\n","print(\"Creating TF-IDF features...\")\n","tfidf_vectorizer = TfidfVectorizer(max_features=5000, min_df=5)\n","\n","# Fit and transform the cleaned tweets\n","X_tfidf = tfidf_vectorizer.fit_transform(df['cleaned_content'])\n","\n","print(f\"TF-IDF features shape: {X_tfidf.shape}\")\n","print(f\"Vocabulary size: {len(tfidf_vectorizer.vocabulary_)}\")\n","\n","# Save TF-IDF features and vectorizer\n","sp.save_npz(tfidf_path, X_tfidf)\n","with open(tfidf_vectorizer_path, 'wb') as f:\n","    pickle.dump(tfidf_vectorizer, f)\n","\n","print(f\"TF-IDF features saved to {tfidf_path}\")\n","print(f\"TF-IDF vectorizer saved to {tfidf_vectorizer_path}\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["Creating TF-IDF features...\n","TF-IDF features shape: (71255, 5000)\n","Vocabulary size: 5000\n","TF-IDF features saved to /content/drive/MyDrive/Colab Notebooks/is5126/final-project/data/features/tfidf_features.npz\n","TF-IDF vectorizer saved to /content/drive/MyDrive/Colab Notebooks/is5126/final-project/models/tfidf_vectorizer.pkl\n"]}]},{"cell_type":"markdown","metadata":{"id":"fWtSMqEafaS-"},"source":["### 5.3 Word2Vec Embeddings"]},{"cell_type":"markdown","metadata":{"id":"mkGFa_A9faS_"},"source":["### 5.4 GloVe Embeddings (Pre-trained)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"czOhE0fPfaS_","executionInfo":{"status":"ok","timestamp":1743679925081,"user_tz":-480,"elapsed":207196,"user":{"displayName":"Wong Matthew","userId":"12913150185447736015"}},"outputId":"b8370d44-13b3-40d7-948c-796db9ea54d4"},"source":["# Download GloVe embeddings if needed\n","import os\n","import requests\n","from zipfile import ZipFile\n","\n","glove_dir = '../data/glove'\n","os.makedirs(glove_dir, exist_ok=True)\n","glove_file = os.path.join(glove_dir, 'glove.6B.100d.txt')\n","\n","# Download GloVe if not already present\n","if not os.path.exists(glove_file):\n","    print(\"Downloading GloVe embeddings...\")\n","    glove_url = \"https://nlp.stanford.edu/data/glove.6B.zip\"\n","    glove_zip = os.path.join(glove_dir, 'glove.6B.zip')\n","\n","    # Download the zip file\n","    response = requests.get(glove_url)\n","    with open(glove_zip, 'wb') as f:\n","        f.write(response.content)\n","\n","    # Extract the zip file\n","    with ZipFile(glove_zip, 'r') as zip_ref:\n","        zip_ref.extractall(glove_dir)\n","\n","    # Remove the zip file to save space\n","    os.remove(glove_zip)\n","    print(\"GloVe embeddings downloaded and extracted.\")\n","else:\n","    print(\"GloVe embeddings already downloaded.\")\n","\n","# Load GloVe embeddings\n","print(\"Loading GloVe embeddings...\")\n","glove_embeddings = {}\n","with open(glove_file, 'r', encoding='utf-8') as f:\n","    for line in f:\n","        values = line.strip().split()\n","        word = values[0]\n","        vector = np.array(values[1:], dtype='float32')\n","        glove_embeddings[word] = vector\n","\n","print(f\"Loaded {len(glove_embeddings)} GloVe word vectors.\")\n","\n","# Function to create document vectors using GloVe\n","def get_glove_vector(tokens, embeddings, vector_size=100):\n","    doc_vector = np.zeros(vector_size)\n","    count = 0\n","\n","    for token in tokens:\n","        if token in embeddings:\n","            doc_vector += embeddings[token]\n","            count += 1\n","\n","    if count > 0:\n","        doc_vector /= count\n","\n","    return doc_vector\n","\n","# Create document vectors for each tweet using GloVe\n","print(\"Generating document vectors from GloVe...\")\n","X_glove = np.array([get_glove_vector(tokens, glove_embeddings) for tokens in df['tokens']])\n","\n","print(f\"GloVe features shape: {X_glove.shape}\")\n","\n","# Save GloVe features\n","np.save(glove_path, X_glove)\n","print(f\"GloVe features saved to {glove_path}\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading GloVe embeddings...\n","GloVe embeddings downloaded and extracted.\n","Loading GloVe embeddings...\n","Loaded 400000 GloVe word vectors.\n","Generating document vectors from GloVe...\n","GloVe features shape: (71255, 100)\n","GloVe features saved to /content/drive/MyDrive/Colab Notebooks/is5126/final-project/data/features/glove_features.npy\n"]}]},{"cell_type":"code","execution_count":10,"metadata":{"id":"NLgPtmiafaS_","executionInfo":{"status":"ok","timestamp":1743677006652,"user_tz":-480,"elapsed":46,"user":{"displayName":"Wong Matthew","userId":"12913150185447736015"}}},"source":["# # Train Word2Vec model on our corpus\n","# print(\"Training Word2Vec model...\")\n","# word2vec_model = Word2Vec(df['tokens'].tolist(),\n","#                           vector_size=100,\n","#                           window=5,\n","#                           min_count=5,\n","#                           workers=4,\n","#                           sg=1) # Skip-gram model\n","\n","# # Save the model for future use\n","# word2vec_model.save(word2vec_model_path)\n","# print(f\"Word2Vec model saved to {word2vec_model_path}\")\n","\n","# # Function to create document vectors by averaging word vectors\n","# def get_doc_vector(tokens, model, vector_size=100):\n","#     # Initialize an empty array\n","#     doc_vector = np.zeros(vector_size)\n","#     count = 0\n","\n","#     # Average the word vectors for each token in the document\n","#     for token in tokens:\n","#         if token in model.wv:\n","#             doc_vector += model.wv[token]\n","#             count += 1\n","\n","#     # Avoid division by zero\n","#     if count > 0:\n","#         doc_vector /= count\n","\n","#     return doc_vector\n","\n","# # Create document vectors for each tweet\n","# print(\"Generating document vectors from Word2Vec...\")\n","# X_word2vec = np.array([get_doc_vector(tokens, word2vec_model) for tokens in df['tokens']])\n","\n","# print(f\"Word2Vec features shape: {X_word2vec.shape}\")\n","\n","# # Save Word2Vec features\n","# np.save(word2vec_path, X_word2vec)\n","# print(f\"Word2Vec features saved to {word2vec_path}\")"],"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i-P1DCg2faTA"},"source":["### 5.5 BERT Embeddings"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n7UAPOP2faTA","executionInfo":{"status":"ok","timestamp":1743677248640,"user_tz":-480,"elapsed":171341,"user":{"displayName":"Wong Matthew","userId":"12913150185447736015"}},"outputId":"eed94b34-fc11-4f48-bdcb-6b978da5887c"},"source":["# Check if GPU is available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# Load pre-trained BERT model and tokenizer\n","print(\"Loading BERT model and tokenizer...\")\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertModel.from_pretrained('bert-base-uncased')\n","model = model.to(device)\n","model.eval()  # Set model to evaluation mode\n","\n","# Function to get BERT embeddings for a batch of texts\n","def get_bert_embeddings(texts, batch_size=32):\n","    all_embeddings = []\n","\n","    for i in range(0, len(texts), batch_size):\n","        batch_texts = texts[i:i+batch_size]\n","\n","        # Tokenize and convert to tensors\n","        encoded_input = tokenizer(batch_texts, padding=True, truncation=True, max_length=128, return_tensors='pt')\n","        encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n","\n","        # Compute token embeddings with no gradient computation\n","        with torch.no_grad():\n","            outputs = model(**encoded_input)\n","\n","        # Use the CLS token representation as the sentence embedding\n","        batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n","        all_embeddings.append(batch_embeddings)\n","\n","        # Print progress\n","        if (i // batch_size) % 10 == 0:\n","            print(f\"Processed {i}/{len(texts)} texts...\")\n","\n","    return np.vstack(all_embeddings)\n","\n","# Generate BERT embeddings for all tweets\n","print(\"Generating BERT embeddings...\")\n","X_bert = get_bert_embeddings(df['cleaned_content'].tolist())\n","\n","print(f\"BERT features shape: {X_bert.shape}\")\n","\n","# Save BERT features\n","np.save(bert_path, X_bert)\n","print(f\"BERT features saved to {bert_path}\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","Loading BERT model and tokenizer...\n","Generating BERT embeddings...\n","Processed 0/71255 texts...\n","Processed 320/71255 texts...\n","Processed 640/71255 texts...\n","Processed 960/71255 texts...\n","Processed 1280/71255 texts...\n","Processed 1600/71255 texts...\n","Processed 1920/71255 texts...\n","Processed 2240/71255 texts...\n","Processed 2560/71255 texts...\n","Processed 2880/71255 texts...\n","Processed 3200/71255 texts...\n","Processed 3520/71255 texts...\n","Processed 3840/71255 texts...\n","Processed 4160/71255 texts...\n","Processed 4480/71255 texts...\n","Processed 4800/71255 texts...\n","Processed 5120/71255 texts...\n","Processed 5440/71255 texts...\n","Processed 5760/71255 texts...\n","Processed 6080/71255 texts...\n","Processed 6400/71255 texts...\n","Processed 6720/71255 texts...\n","Processed 7040/71255 texts...\n","Processed 7360/71255 texts...\n","Processed 7680/71255 texts...\n","Processed 8000/71255 texts...\n","Processed 8320/71255 texts...\n","Processed 8640/71255 texts...\n","Processed 8960/71255 texts...\n","Processed 9280/71255 texts...\n","Processed 9600/71255 texts...\n","Processed 9920/71255 texts...\n","Processed 10240/71255 texts...\n","Processed 10560/71255 texts...\n","Processed 10880/71255 texts...\n","Processed 11200/71255 texts...\n","Processed 11520/71255 texts...\n","Processed 11840/71255 texts...\n","Processed 12160/71255 texts...\n","Processed 12480/71255 texts...\n","Processed 12800/71255 texts...\n","Processed 13120/71255 texts...\n","Processed 13440/71255 texts...\n","Processed 13760/71255 texts...\n","Processed 14080/71255 texts...\n","Processed 14400/71255 texts...\n","Processed 14720/71255 texts...\n","Processed 15040/71255 texts...\n","Processed 15360/71255 texts...\n","Processed 15680/71255 texts...\n","Processed 16000/71255 texts...\n","Processed 16320/71255 texts...\n","Processed 16640/71255 texts...\n","Processed 16960/71255 texts...\n","Processed 17280/71255 texts...\n","Processed 17600/71255 texts...\n","Processed 17920/71255 texts...\n","Processed 18240/71255 texts...\n","Processed 18560/71255 texts...\n","Processed 18880/71255 texts...\n","Processed 19200/71255 texts...\n","Processed 19520/71255 texts...\n","Processed 19840/71255 texts...\n","Processed 20160/71255 texts...\n","Processed 20480/71255 texts...\n","Processed 20800/71255 texts...\n","Processed 21120/71255 texts...\n","Processed 21440/71255 texts...\n","Processed 21760/71255 texts...\n","Processed 22080/71255 texts...\n","Processed 22400/71255 texts...\n","Processed 22720/71255 texts...\n","Processed 23040/71255 texts...\n","Processed 23360/71255 texts...\n","Processed 23680/71255 texts...\n","Processed 24000/71255 texts...\n","Processed 24320/71255 texts...\n","Processed 24640/71255 texts...\n","Processed 24960/71255 texts...\n","Processed 25280/71255 texts...\n","Processed 25600/71255 texts...\n","Processed 25920/71255 texts...\n","Processed 26240/71255 texts...\n","Processed 26560/71255 texts...\n","Processed 26880/71255 texts...\n","Processed 27200/71255 texts...\n","Processed 27520/71255 texts...\n","Processed 27840/71255 texts...\n","Processed 28160/71255 texts...\n","Processed 28480/71255 texts...\n","Processed 28800/71255 texts...\n","Processed 29120/71255 texts...\n","Processed 29440/71255 texts...\n","Processed 29760/71255 texts...\n","Processed 30080/71255 texts...\n","Processed 30400/71255 texts...\n","Processed 30720/71255 texts...\n","Processed 31040/71255 texts...\n","Processed 31360/71255 texts...\n","Processed 31680/71255 texts...\n","Processed 32000/71255 texts...\n","Processed 32320/71255 texts...\n","Processed 32640/71255 texts...\n","Processed 32960/71255 texts...\n","Processed 33280/71255 texts...\n","Processed 33600/71255 texts...\n","Processed 33920/71255 texts...\n","Processed 34240/71255 texts...\n","Processed 34560/71255 texts...\n","Processed 34880/71255 texts...\n","Processed 35200/71255 texts...\n","Processed 35520/71255 texts...\n","Processed 35840/71255 texts...\n","Processed 36160/71255 texts...\n","Processed 36480/71255 texts...\n","Processed 36800/71255 texts...\n","Processed 37120/71255 texts...\n","Processed 37440/71255 texts...\n","Processed 37760/71255 texts...\n","Processed 38080/71255 texts...\n","Processed 38400/71255 texts...\n","Processed 38720/71255 texts...\n","Processed 39040/71255 texts...\n","Processed 39360/71255 texts...\n","Processed 39680/71255 texts...\n","Processed 40000/71255 texts...\n","Processed 40320/71255 texts...\n","Processed 40640/71255 texts...\n","Processed 40960/71255 texts...\n","Processed 41280/71255 texts...\n","Processed 41600/71255 texts...\n","Processed 41920/71255 texts...\n","Processed 42240/71255 texts...\n","Processed 42560/71255 texts...\n","Processed 42880/71255 texts...\n","Processed 43200/71255 texts...\n","Processed 43520/71255 texts...\n","Processed 43840/71255 texts...\n","Processed 44160/71255 texts...\n","Processed 44480/71255 texts...\n","Processed 44800/71255 texts...\n","Processed 45120/71255 texts...\n","Processed 45440/71255 texts...\n","Processed 45760/71255 texts...\n","Processed 46080/71255 texts...\n","Processed 46400/71255 texts...\n","Processed 46720/71255 texts...\n","Processed 47040/71255 texts...\n","Processed 47360/71255 texts...\n","Processed 47680/71255 texts...\n","Processed 48000/71255 texts...\n","Processed 48320/71255 texts...\n","Processed 48640/71255 texts...\n","Processed 48960/71255 texts...\n","Processed 49280/71255 texts...\n","Processed 49600/71255 texts...\n","Processed 49920/71255 texts...\n","Processed 50240/71255 texts...\n","Processed 50560/71255 texts...\n","Processed 50880/71255 texts...\n","Processed 51200/71255 texts...\n","Processed 51520/71255 texts...\n","Processed 51840/71255 texts...\n","Processed 52160/71255 texts...\n","Processed 52480/71255 texts...\n","Processed 52800/71255 texts...\n","Processed 53120/71255 texts...\n","Processed 53440/71255 texts...\n","Processed 53760/71255 texts...\n","Processed 54080/71255 texts...\n","Processed 54400/71255 texts...\n","Processed 54720/71255 texts...\n","Processed 55040/71255 texts...\n","Processed 55360/71255 texts...\n","Processed 55680/71255 texts...\n","Processed 56000/71255 texts...\n","Processed 56320/71255 texts...\n","Processed 56640/71255 texts...\n","Processed 56960/71255 texts...\n","Processed 57280/71255 texts...\n","Processed 57600/71255 texts...\n","Processed 57920/71255 texts...\n","Processed 58240/71255 texts...\n","Processed 58560/71255 texts...\n","Processed 58880/71255 texts...\n","Processed 59200/71255 texts...\n","Processed 59520/71255 texts...\n","Processed 59840/71255 texts...\n","Processed 60160/71255 texts...\n","Processed 60480/71255 texts...\n","Processed 60800/71255 texts...\n","Processed 61120/71255 texts...\n","Processed 61440/71255 texts...\n","Processed 61760/71255 texts...\n","Processed 62080/71255 texts...\n","Processed 62400/71255 texts...\n","Processed 62720/71255 texts...\n","Processed 63040/71255 texts...\n","Processed 63360/71255 texts...\n","Processed 63680/71255 texts...\n","Processed 64000/71255 texts...\n","Processed 64320/71255 texts...\n","Processed 64640/71255 texts...\n","Processed 64960/71255 texts...\n","Processed 65280/71255 texts...\n","Processed 65600/71255 texts...\n","Processed 65920/71255 texts...\n","Processed 66240/71255 texts...\n","Processed 66560/71255 texts...\n","Processed 66880/71255 texts...\n","Processed 67200/71255 texts...\n","Processed 67520/71255 texts...\n","Processed 67840/71255 texts...\n","Processed 68160/71255 texts...\n","Processed 68480/71255 texts...\n","Processed 68800/71255 texts...\n","Processed 69120/71255 texts...\n","Processed 69440/71255 texts...\n","Processed 69760/71255 texts...\n","Processed 70080/71255 texts...\n","Processed 70400/71255 texts...\n","Processed 70720/71255 texts...\n","Processed 71040/71255 texts...\n","BERT features shape: (71255, 768)\n","BERT features saved to /content/drive/MyDrive/Colab Notebooks/is5126/final-project/data/features/bert_features.npy\n"]}]},{"cell_type":"markdown","metadata":{"id":"FWCWVrAjfaTA"},"source":["## 6. Feature Analysis"]},{"cell_type":"markdown","metadata":{"id":"o69hJIULfaTA"},"source":["### 6.1 Compare Feature Dimensionality"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"g9A2SI-mfaTA","executionInfo":{"status":"ok","timestamp":1743680064353,"user_tz":-480,"elapsed":174,"user":{"displayName":"Wong Matthew","userId":"12913150185447736015"}},"outputId":"daba6659-f7be-4769-9817-3ef3066403a0"},"source":["X_word2vec = np.load(word2vec_path)\n","\n","# Create a comparison table of feature dimensions\n","feature_info = {\n","    'Feature Type': ['Bag of Words', 'TF-IDF', 'Word2Vec', 'GloVe', 'BERT'],\n","    'Dimensions': [X_bow.shape[1], X_tfidf.shape[1], X_word2vec.shape[1], X_glove.shape[1], X_bert.shape[1]],\n","    'Data Type': ['Sparse', 'Sparse', 'Dense', 'Dense', 'Dense']\n","}\n","\n","# Create DataFrame for display\n","feature_df = pd.DataFrame(feature_info)\n","feature_df"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Feature Type  Dimensions Data Type\n","0  Bag of Words        5000    Sparse\n","1        TF-IDF        5000    Sparse\n","2      Word2Vec         100     Dense\n","3         GloVe         100     Dense\n","4          BERT         768     Dense"],"text/html":["\n","  <div id=\"df-7e84d48e-2126-4421-aeb3-135e412d6b9d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Feature Type</th>\n","      <th>Dimensions</th>\n","      <th>Data Type</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Bag of Words</td>\n","      <td>5000</td>\n","      <td>Sparse</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TF-IDF</td>\n","      <td>5000</td>\n","      <td>Sparse</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Word2Vec</td>\n","      <td>100</td>\n","      <td>Dense</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>GloVe</td>\n","      <td>100</td>\n","      <td>Dense</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>BERT</td>\n","      <td>768</td>\n","      <td>Dense</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e84d48e-2126-4421-aeb3-135e412d6b9d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7e84d48e-2126-4421-aeb3-135e412d6b9d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7e84d48e-2126-4421-aeb3-135e412d6b9d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-f6ace597-fff8-43a6-a815-afd6047d1eba\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f6ace597-fff8-43a6-a815-afd6047d1eba')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-f6ace597-fff8-43a6-a815-afd6047d1eba button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_85810ba5-0bca-4057-8852-7d8bdbdf8d5e\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('feature_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_85810ba5-0bca-4057-8852-7d8bdbdf8d5e button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('feature_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"feature_df","summary":"{\n  \"name\": \"feature_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Feature Type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"TF-IDF\",\n          \"BERT\",\n          \"Word2Vec\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dimensions\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2576,\n        \"min\": 100,\n        \"max\": 5000,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5000,\n          100,\n          768\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Data Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Dense\",\n          \"Sparse\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"XZ0RPp6MfaTA"},"source":["### 6.2 Visualize Word2Vec Embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eJqECZemfaTA"},"source":["# # Visualize Word2Vec embeddings using t-SNE\n","# from sklearn.manifold import TSNE\n","\n","# # Get vocabulary and vectors\n","# vocab = list(word2vec_model.wv.index_to_key)\n","# vectors = [word2vec_model.wv[word] for word in vocab]\n","\n","# # Limit to 1000 most frequent words for visualization\n","# top_n = min(1000, len(vocab))\n","# vocab = vocab[:top_n]\n","# vectors = vectors[:top_n]\n","\n","# # Apply t-SNE for dimensionality reduction\n","# tsne = TSNE(n_components=2, random_state=42)\n","# vectors_2d = tsne.fit_transform(vectors)\n","\n","# # Plot\n","# plt.figure(figsize=(14, 10))\n","# plt.scatter(vectors_2d[:, 0], vectors_2d[:, 1], s=10, alpha=0.5)\n","\n","# # Annotate some interesting words if they exist in the vocabulary\n","# interesting_words = ['good', 'bad', 'awesome', 'terrible', 'happy', 'sad', 'game', 'play', 'win', 'lose']\n","# for word in interesting_words:\n","#     if word in vocab:\n","#         idx = vocab.index(word)\n","#         plt.annotate(word, vectors_2d[idx], fontsize=12)\n","\n","# plt.title('t-SNE Visualization of Word2Vec Embeddings')\n","# plt.xlabel('Dimension 1')\n","# plt.ylabel('Dimension 2')\n","# plt.show()"],"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7yAVjnKBfaTB"},"source":["### 6.3 Visualize Document-Level Embeddings"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1TFx620FUcPPrR4lb1K218bI2zl22pPsC"},"id":"vlIgoMdbfaTB","executionInfo":{"status":"ok","timestamp":1743680696340,"user_tz":-480,"elapsed":25436,"user":{"displayName":"Wong Matthew","userId":"12913150185447736015"}},"outputId":"7cc6abbd-0862-4921-bcea-fe7a361bce80"},"source":["# Compare distributions of different embeddings\n","from sklearn.decomposition import PCA\n","\n","# Function to reduce dimensions and plot\n","def plot_embedding_distribution(embeddings, title, target=y):\n","    # Reduce to 2D with PCA\n","    pca = PCA(n_components=2)\n","    reduced_embeddings = pca.fit_transform(embeddings)\n","\n","    # Create DataFrame for easy plotting\n","    df_plot = pd.DataFrame({\n","        'x': reduced_embeddings[:, 0],\n","        'y': reduced_embeddings[:, 1],\n","        'sentiment': [label_encoder.classes_[i] for i in target]\n","    })\n","\n","    # Plot\n","    plt.figure(figsize=(10, 8))\n","    sns.scatterplot(data=df_plot, x='x', y='y', hue='sentiment', alpha=0.6)\n","    plt.title(f'PCA Visualization of {title}')\n","    plt.xlabel('Principal Component 1')\n","    plt.ylabel('Principal Component 2')\n","    variance = pca.explained_variance_ratio_\n","    plt.figtext(0.5, 0.01, f'Explained variance: PC1 {variance[0]:.2%}, PC2 {variance[1]:.2%}', ha='center')\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Plot Word2Vec embeddings\n","plot_embedding_distribution(X_word2vec, 'Word2Vec Embeddings')\n","\n","# Plot GloVe embeddings\n","plot_embedding_distribution(X_glove, 'GloVe Embeddings')\n","\n","# Plot BERT embeddings (sample for faster visualization)\n","plot_embedding_distribution(X_bert, 'BERT Embeddings')"],"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"_5dwld_ZfaTB"},"source":["## 7. Summary and Next Steps"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qHyJGX0mfaTB","executionInfo":{"status":"ok","timestamp":1743680082918,"user_tz":-480,"elapsed":9,"user":{"displayName":"Wong Matthew","userId":"12913150185447736015"}},"outputId":"4899e3a3-a6fa-4103-bd53-d1cf6043f709"},"source":["# Save the label and indices for train/val/test splits\n","np.save(os.path.join(features_dir, 'labels.npy'), y)\n","print(f\"Labels saved to {os.path.join(features_dir, 'labels.npy')}\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["Labels saved to /content/drive/MyDrive/Colab Notebooks/is5126/final-project/data/features/labels.npy\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}